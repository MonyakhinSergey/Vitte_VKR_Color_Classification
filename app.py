# -*- coding: utf-8 -*-
"""
Streamlit-Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ: Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ Ğ´Ğ¾Ğ¼Ğ¸Ğ½Ğ¸Ñ€ÑƒÑÑ‰Ğ¸Ğ¹ Ñ†Ğ²ĞµÑ‚ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ.
CNN â†’ Ğ¾Ğ±ÑĞ·Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ°Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ° GPT-4o-mini (proxyapi.ru).
"""

import os, io, base64, sqlite3, time, numpy as np, pandas as pd
from PIL import Image
import streamlit as st
from functools import lru_cache
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image as kimage
import openai

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1. OpenAI Ñ‡ĞµÑ€ĞµĞ· Ñ€Ğ¾ÑÑĞ¸Ğ¹ÑĞºĞ¸Ğ¹ Ğ¿Ñ€Ğ¾ĞºÑĞ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
PROXY_BASE_URL = "https://api.proxyapi.ru/openai/v1"
PROXY_API_KEY  = "sk-2uHtBOkjr3ZrCn43aUt4WdEZ20JaXu49"   # â† Ğ²Ğ°Ñˆ ĞºĞ»ÑÑ‡

@lru_cache(maxsize=1)
def get_client() -> openai.OpenAI:
    return openai.OpenAI(
        api_key=PROXY_API_KEY,
        base_url=PROXY_BASE_URL,
        timeout=60,
    )

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2. Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° CNN-Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
MODEL_PATH = "modified_model.h5"
model = load_model(MODEL_PATH)

class_labels = [
    "black", "blue", "brown", "green", "grey", "orange",
    "pink", "purple", "red", "silver", "white", "yellow"
]

def predict_color_cnn(img: Image.Image):
    arr = kimage.img_to_array(img.resize((160, 160))) / 255.0
    arr = np.expand_dims(arr, axis=0)
    preds = model.predict(arr, verbose=0)
    preds = preds[0] if preds.ndim > 1 else preds
    if preds.size == 0:
        return "unknown", 0.0
    idx  = int(np.argmax(preds))
    conf = float(np.max(preds))
    return (class_labels[idx] if idx < len(class_labels) else "unknown", conf)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3. GPT-4o-mini: Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ğ¸Ğµ/Ğ¸ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
GPT_PROMPT = (
    "You are an expert assistant. Identify the single English word that best "
    "describes the dominant color in the given image. "
    "Only respond with that word in lowercase (e.g. 'red')."
)

def image_to_b64(img: Image.Image, side: int = 256) -> str:
    img = img.copy()
    img.thumbnail((side, side))
    buf = io.BytesIO()
    img.save(buf, format="PNG")
    return base64.b64encode(buf.getvalue()).decode()

def correct_color_with_gpt(img: Image.Image, fallback: str) -> str:
    client = get_client()
    b64 = image_to_b64(img)
    messages = [
        {"role": "system", "content": GPT_PROMPT},
        {"role": "user", "content": [
            {"type": "input_text",
             "text": "What is the dominant color in this image? respond only with the color word."},
            {"type": "input_image",
             "image_url": f"data:image/png;base64,{b64}"}
        ]}
    ]
    try:
        resp = client.responses.create(
            model="gpt-4o-mini",
            input=messages,
            temperature=0.0,
            max_output_tokens=16      # â‰¥ 16   â† Ğ¸ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¾
        )
        if hasattr(resp, "output") and resp.output:
            gpt_ans = resp.output[0].content[0].text.strip().lower()
            if gpt_ans in class_labels:
                return gpt_ans
    except Exception as e:
        st.warning(f"âš ï¸ GPT-Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ Ğ½Ğµ ÑƒĞ´Ğ°Ğ»ÑÑ: {e}")
    return fallback

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4. Ğ‘Ğ°Ğ·Ğ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… (SQLite) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DB_PATH = "predictions.db"
def init_db():
    with sqlite3.connect(DB_PATH) as conn:
        # ĞµÑĞ»Ğ¸ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ‹ Ğ½ĞµÑ‚ â€“ ÑĞ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ ÑĞ¾ Ğ²ÑĞµĞ¼Ğ¸ Ğ½ÑƒĞ¶Ğ½Ñ‹Ğ¼Ğ¸ Ğ¿Ğ¾Ğ»ÑĞ¼Ğ¸
        conn.execute("""
            CREATE TABLE IF NOT EXISTS predictions (
              id INTEGER PRIMARY KEY AUTOINCREMENT,
              image_path TEXT,
              predicted_class TEXT,
              confidence REAL,
              corrected INTEGER DEFAULT 0,
              timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        """)
        # ĞµÑĞ»Ğ¸ ĞºĞ¾Ğ»Ğ¾Ğ½ĞºĞ° corrected Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒĞµÑ‚ (ÑÑ‚Ğ°Ñ€Ñ‹Ğ¹ Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ‹) â€“ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ¸Ğ¼
        cur = conn.execute("PRAGMA table_info(predictions)")
        cols = [row[1] for row in cur.fetchall()]
        if "corrected" not in cols:
            conn.execute("ALTER TABLE predictions ADD COLUMN corrected INTEGER DEFAULT 0")

def save_pred(path, cls, conf, corr):
    with sqlite3.connect(DB_PATH) as conn:
        conn.execute(
            "INSERT INTO predictions (image_path, predicted_class, confidence, corrected)"
            "VALUES (?,?,?,?)",
            (path, cls, conf, int(corr))
        )

def load_preds():
    with sqlite3.connect(DB_PATH) as conn:
        return pd.read_sql("SELECT * FROM predictions", conn)

init_db()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 5. Streamlit-Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹Ñ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ñ†Ğ²ĞµÑ‚Ğ°", page_icon="ğŸ¨")
st.title("ğŸ–¼ï¸ ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ğ´Ğ¾Ğ¼Ğ¸Ğ½Ğ¸Ñ€ÑƒÑÑ‰ĞµĞ³Ğ¾ Ñ†Ğ²ĞµÑ‚Ğ°")

section = st.sidebar.radio("ĞĞ°Ğ²Ğ¸Ğ³Ğ°Ñ†Ğ¸Ñ", ["Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ", "Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°"])

if section == "Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ":
    st.subheader("Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ")
    uploaded = st.file_uploader("Ğ¤Ğ°Ğ¹Ğ» (jpg/png)", type=["jpg", "jpeg", "png"])

    if uploaded:
        img = Image.open(uploaded).convert("RGB")
        st.image(img, caption="Ğ˜ÑÑ…Ğ¾Ğ´Ğ½Ğ¾Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ", use_container_width=True)

        os.makedirs("uploads", exist_ok=True)
        path = os.path.join("uploads", uploaded.name)
        img.save(path)

        # 1) Ğ¿Ñ€Ğ¾Ğ³Ğ½Ğ¾Ğ· CNN
        cnn_class, cnn_conf = predict_color_cnn(img)

        # 2) Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ğ¸Ğµ GPT-4o-mini
        final_class = correct_color_with_gpt(img, cnn_class)
        corrected   = final_class != cnn_class

        txt = f"Ğ¦Ğ²ĞµÑ‚: **{final_class}**  \nĞ£Ğ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ CNN: {cnn_conf:.2f}"
        if corrected or cnn_class == "unknown":
            txt += "  \n*(ÑƒÑ‚Ğ¾Ñ‡Ğ½ĞµĞ½Ğ¾ GPT-4o-mini)*"
        st.success(txt)

        save_pred(path, final_class, cnn_conf, corrected)

elif section == "Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°":
    st.subheader("Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ğ¹")
    df = load_preds()
    if df.empty:
        st.info("ĞŸĞ¾ĞºĞ° Ğ½ĞµÑ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ….")
    else:
        st.dataframe(df)
        st.bar_chart(df.groupby("predicted_class").size())

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 6. Ğ—Ğ°Ğ¿ÑƒÑĞº ÑĞºÑ€Ğ¸Ğ¿Ñ‚Ğ° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    from streamlit import runtime
    import sys
    from streamlit.web import cli as stcli
    if not runtime.exists():          # Ğ·Ğ°Ğ¿ÑƒÑĞº Ğ¸Ğ· ĞºĞ¾Ğ½ÑĞ¾Ğ»Ğ¸:  python this.py
        sys.argv = ["streamlit", "run", sys.argv[0]]
        sys.exit(stcli.main())
